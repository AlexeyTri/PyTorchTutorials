{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7kc0b7zWPGraIi3NY23j8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexeyTri/PyTorchTutorials/blob/main/Tutorial14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVE_LOAD**"
      ],
      "metadata": {
        "id": "j9RGI6Z-jKtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "uD3gQu6zrziQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 главных метода для запоминания:**\n",
        "\n",
        "- torch.save(arg, PATH) используют для модели, тензора, словаря параметров модели\n",
        "\n",
        "- torch.load(PATH)\n",
        "\n",
        "- torch.load_state_dict(arg) загрузка словаря параметров\n",
        "\n",
        "**два основных метода для save**\n",
        "\n",
        "1) lazy way: save whole model\n",
        "torch.save(model, PATH)\n",
        "\n",
        "! model class must be diferent somewhere\n",
        "model = torch.load(PATH)\n",
        "model.eval() !remember that you must call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference.\n",
        "\n",
        "2) recomended way: save only the state_dict\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "! model must be created again with parameters\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "0_lOXZFLr-Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "BtZGfE-drzkw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(n_input_features=6)\n",
        "# train model"
      ],
      "metadata": {
        "id": "VDka4p4PrzoJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save all"
      ],
      "metadata": {
        "id": "R7XuwpsIzTx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB0bZ5_yyeR9",
        "outputId": "1df36416-e79b-4dce-84f3-21f86add04fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3525,  0.1465,  0.0286, -0.3435, -0.3470, -0.1081]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2313], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/sample_data/model.pth'\n",
        "torch.save(model, PATH)"
      ],
      "metadata": {
        "id": "gU_oULZ7yelv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = torch.load(PATH)\n",
        "loaded_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndAu_tuDyeqQ",
        "outputId": "16a93299-6866-4247-b17d-c21c188c6e52"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (linear): Linear(in_features=6, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in loaded_model.parameters():\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxvNJbQpyeui",
        "outputId": "9a2e43c8-9a36-4b02-af32-e86c125ba5b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3525,  0.1465,  0.0286, -0.3435, -0.3470, -0.1081]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2313], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "save only state_dict"
      ],
      "metadata": {
        "id": "OvWgMSrI0k3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/sample_data/model2.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "e4k0sJDnyeyT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU2Ed2O-ye1u",
        "outputId": "70268712-c326-428a-96ad-ba9925d7703a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('linear.weight', tensor([[-0.3525,  0.1465,  0.0286, -0.3435, -0.3470, -0.1081]])), ('linear.bias', tensor([-0.2313]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = Model(n_input_features=6)\n",
        "load_model.load_state_dict(torch.load(PATH))\n",
        "print(load_model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TuxrQXJye5S",
        "outputId": "5b56567a-330a-49a2-8da2-e95a835e3e63"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('linear.weight', tensor([[-0.3525,  0.1465,  0.0286, -0.3435, -0.3470, -0.1081]])), ('linear.bias', tensor([-0.2313]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load checkpoint"
      ],
      "metadata": {
        "id": "qWHqyImS3if6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "BYuI-BH0ye9B"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint={\n",
        "    \"epoch\": 50,\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"optim_state\": optimizer.state_dict()\n",
        "}"
      ],
      "metadata": {
        "id": "jttIOOWJye_s"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(optimizer.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Osmxo-ZryfDH",
        "outputId": "311b490c-7681-487a-aea0-cc89a960e844"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(checkpoint, '/content/sample_data/checkpoint.pth')"
      ],
      "metadata": {
        "id": "oOBa5s5jyfGk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('/content/sample_data/checkpoint.pth')"
      ],
      "metadata": {
        "id": "9bJBElxUyfI-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(n_input_features=6)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "C2qSrd2lrzq4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(checkpoint['model_state'])\n",
        "optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "epoch = checkpoint['epoch']"
      ],
      "metadata": {
        "id": "F73Zb-M2rzt0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # -or- model.train()\n",
        "print(optimizer.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUZMKOuR55LC",
        "outputId": "b8918520-27e8-4aae-fe73-d4e1394140fe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# !\n",
        "\n",
        "* remember that you must call model.eval() to set dropout and batch notmalization layers\n",
        "\n",
        "* to evaluation mode before running inference. Failing to do thid will yeild inconsisntent inference results. If you wish to resuming training, call model.train() to ensure these layers are in training mode"
      ],
      "metadata": {
        "id": "ZqWcx9Zn6ea3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\" SAVING ON GPU/CPU \n",
        "\n",
        "# 1) Save on GPU, Load on CPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "device = torch.device('cpu')\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=device))\n",
        "\n",
        "# 2) Save on GPU, Load on GPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.to(device)\n",
        "\n",
        "# Note: Be sure to use the .to(torch.device('cuda')) function \n",
        "# on all model inputs, too!\n",
        "\n",
        "# 3) Save on CPU, Load on GPU\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n",
        "model.to(device)\n",
        "\n",
        "# This loads the model to a given GPU device. \n",
        "# Next, be sure to call model.to(torch.device('cuda')) to convert the model’s parameter tensors to CUDA tensors\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "G2uAVdoq79Ag"
      }
    }
  ]
}